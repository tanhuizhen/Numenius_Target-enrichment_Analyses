{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35816b6-fbcb-40b5-8d6a-ce6f4411b597",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Content\n",
    "1. [Inputs](#inputs)\n",
    "    1. [Occurrence records](#occurrenceRecords)\n",
    "    2. [Kernel density estimate and background points](#kdeBg)\n",
    "    3. [Bioclimatic variables](#biovar)\n",
    "2. [Maxent modelling](#maxent) <br>\n",
    "3. [Maxent results](#results)\n",
    "\n",
    "**All codes in this section were implemented in R unless otherwise stated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905aafdf-5523-45b4-98d3-c1f4f90a258c",
   "metadata": {},
   "source": [
    "## 1. Inputs <a id='inputs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427e1d1-7555-4988-a8e4-8e988fda8d11",
   "metadata": {},
   "source": [
    "### A. Occurrence records <a id='occurrenceRecords'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00642046-9729-4e42-bf6b-500fc10071b4",
   "metadata": {},
   "source": [
    "Obtain species occurrence records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7b2d3-ea18-4322-9112-499655146ced",
   "metadata": {},
   "source": [
    "1. eBird basic data: https://ebird.org/data/download\n",
    "2. Global Biodiversity Information Facility (GBIF): https://www.gbif.org/occurrence/search?occurrence_status=present&q="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58635373-b1e6-4e66-866f-5fe7c12573b4",
   "metadata": {},
   "source": [
    "Filter and thin occurrence records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3c4bd-b9d1-4878-a79c-cb13ac001947",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages\n",
    "library(tidyr)\n",
    "library(spThin)\n",
    "library(stringr)\n",
    "library(sp)\n",
    "library(rgdal)\n",
    "library(spatialEco)\n",
    "library(raster)\n",
    "\n",
    "## import occurrence records\n",
    "# eBird\n",
    "data <- read.delim(\"ebd_species_relMonth-yyyy.txt\", quote=\"\") # import file \n",
    "data2 <- data[!duplicated(data[c(\"LATITUDE\",\"LONGITUDE\")]),] # remove duplicates based on latitude and longitude\n",
    "# split date into year month day columns\n",
    "ymd <- str_split_fixed(data2$OBSERVATION.DATE, \"-\", 3)\n",
    "ymd2 <- as.data.frame(ymd)\n",
    "colnames(ymd2) <- c(\"Year\", \"Month\",\"Date\")\n",
    "ymd2$Year <- as.numeric(as.character(ymd2$Year))\n",
    "ymd2$Month <- as.numeric(as.character(ymd2$Month))\n",
    "ymd2$Date <- as.numeric(as.character(ymd2$Date))\n",
    "data3 <- cbind(data2, ymd2)\n",
    "data4 <- data3[data3$Month>3 & data3$Month<7, ] # subset records from Apr to Jun\n",
    "data5 <- data4[data4$Year>1959 & data4$Year<1991, ] # subset records from 1960-1990\n",
    "ebird <- data5[, c(\"LONGITUDE\", \"LATITUDE\")] # create new dataframe with longitude and latitude\n",
    "\n",
    "# GBIF\n",
    "gdata <- read.csv(file = 'species-gbif.csv', header = TRUE) # import file\n",
    "gdata2 <- gdata[!duplicated(gdata[c(\"decimalLatitude\",\"decimalLongitude\")]),] # remove duplicates based on latitude and longitude\n",
    "# split date into year month day columns\n",
    "library(stringr)\n",
    "gdata2$year <- as.numeric(as.character(gdata2$year))\n",
    "gdata2$month <- as.numeric(as.character(gdata2$month))\n",
    "gdata2$day <- as.numeric(as.character(gdata2$day))\n",
    "gdata3 <- gdata2[gdata2$month>3 & gdata2$month<7, ] # subset records from Apr to Jun\n",
    "gdata4 <- gdata3[gdata3$year>1959 & gdata3$year<1991, ] # subset records from 1960-1990\n",
    "gbif <- gdata4[, c(\"decimalLongitude\", \"decimalLatitude\")] # create new dataframe with longitude and latitude\n",
    "colnames(gbif) <- c(\"LONGITUDE\", \"LATITUDE\")\n",
    "\n",
    "## combine eBird and GBIF occurrence records\n",
    "species <- rbind(ebird, gbif)\n",
    "species2 <- species[!duplicated(species[c(\"LATITUDE\",\"LONGITUDE\")]),] # remove duplicates based on latitude and longitude\n",
    "species3 <- species2 %>% drop_na(LONGITUDE) # remove NA rows\n",
    "\n",
    "## remove points outside of IUCN/eBird breeding area\n",
    "Breeding <- readOGR(dsn = \"path/species\", layer = \"speciesBr\")\n",
    "species4 <- SpatialPoints(species3) # make into r SpatialPointsDataFrame\n",
    "species5 <- erase.point(species4, Breeding, inside = FALSE)\n",
    "species6 <- as.data.frame(species5)\n",
    "species7 <- cbind(a = \"Genus species\", species6)\n",
    "colnames(species7) <- c(\"species\", \"longitude\", \"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80897e0f-5631-4f53-8edd-298b89015760",
   "metadata": {},
   "source": [
    "Downsample occurrence records for *N. phaeopus* and *N. arquata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f309e9-1ab7-4654-acfe-3150778121a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "library(rgdal)\n",
    "library(spatialEco)\n",
    "library(sf)\n",
    "library(maptools)\n",
    "library(raster)\n",
    "library(spatstat)\n",
    "\n",
    "# import occurence file\n",
    "occ <- read.csv(file = 'occurrence-species-all-1960to1990-AprJun.csv', header = TRUE)\n",
    "occ1 <- occ[,-1]\n",
    "\n",
    "# extract records inside and outside of Europe\n",
    "occ1sp <- SpatialPoints(occ1)\n",
    "eur <- readOGR(dsn = \"shapefile/folder\", layer = \"Europe\")\n",
    "eurSp <- erase.point(occ1sp, eur, inside = FALSE)\n",
    "othSp <- erase.point(occ1sp, eur, inside = TRUE)\n",
    "\n",
    "# convert to dataframe\n",
    "othOcc <- as.data.frame(othSp)\n",
    "eurOcc <- as.data.frame(eurSp)\n",
    "\n",
    "## calculate density of occurrence records\n",
    "# outside Europe\n",
    "othPPP <- as.ppp(othSp)\n",
    "othDen <- intensity(othPPP)\n",
    "# inside Europe\n",
    "eurPPP <- as.ppp(eurSp)\n",
    "eurDen <- intensity(eurPPP)\n",
    "# number of pts to retain in Europe\n",
    "(othDen/eurDen) * nrow(eurOcc)\n",
    "\n",
    "# thin occurrence records inside Europe\n",
    "set.seed(123)\n",
    "eurSub <- eurOcc[sample(nrow(eurOcc), 227), ]\n",
    "# check density\n",
    "eurSubSp <- SpatialPoints(eurSub)\n",
    "eur2PPP <- as.ppp(eurSubSp)\n",
    "intensity(othPPP)\n",
    "intensity(eur2PPP)\n",
    "\n",
    "# combine pts\n",
    "sp <- rbind(othOcc, eurSub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf550846-fd20-4c47-9380-0ee5d1c8f516",
   "metadata": {},
   "source": [
    "### B. Kernel density estimate and background points <a id='kdeBg'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5222b4-6e73-45ad-bc93-2601cf529fe7",
   "metadata": {},
   "source": [
    "Generate kernel density estimate and sample background points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa43191-e311-4300-9c2e-c4482470e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "library(raster)\n",
    "library(spatialEco)\n",
    "\n",
    "occ.pts <- read.csv('Shorebird_sampling_proc.csv') # x y or lon lat points of occurrence\n",
    "occ.pts <- occ.pts[, c('gbifID', 'decimalLongitude', 'decimalLatitude')]\n",
    "occ.pts$taxa <- \"Scolopacidae\"\n",
    "coordinates(occ.pts) <- ~decimalLongitude + decimalLatitude\n",
    "crs(occ.pts) <- CRS('+init=EPSG:4326')\n",
    "\n",
    "sp.list <- c(\"americanus\", \"arquata\", \"hudsonicus\", \"phaeopus\")\n",
    "sp <- sp.list[1]\n",
    "for(sp in sp.list) {\n",
    "  #### running bias file ####\n",
    "  setwd(main)\n",
    "  setwd('data')\n",
    "  setwd(sp); sp.dir <- getwd()\n",
    "  sp.occ <- read.csv(list.files(pattern = 'occurrence'))\n",
    "  sp.pts <- sp.occ\n",
    "  coordinates(sp.pts) <- ~longitude + latitude\n",
    "  \n",
    "  setwd('current-v1.4-r2.5')\n",
    "  ref_lay <- raster('bio1.asc') # reference raster layer\n",
    "  crs(ref_lay) <- CRS('+init=EPSG:4326')\n",
    "  # WGS 84 lat/lon (EPSG 4326)\n",
    "  \n",
    "  bias.pts <- raster::crop(occ.pts, ref_lay)\n",
    "  if(nrow(bias.pts) > 20000) { # if file size too big, break down thinning\n",
    "    j.n <- min(floor(nrow(bias.pts) / 10000), 10)\n",
    "    set.seed(1734)\n",
    "    bias.list <- bias.pts[sample(1:nrow(bias.pts), 10000 * j.n), ]\n",
    "    for (j in 1:j.n) {\n",
    "      bias.sub <- bias.list[(1:10000) + (j-1)*10000, ]\n",
    "      st <- Sys.time()\n",
    "      thin.sub <- spThin::thin(cbind(bias.sub, bias.sub@coords), long.col = 'decimalLongitude', lat.col = 'decimalLatitude', spec.col = 'taxa',\n",
    "                               thin.par = 50, reps = 1, max.files = 1, out.base = sp, locs.thinned.list.return = T,\n",
    "                               out.dir = op, write.files = F, write.log.file = F, verbose = F)\n",
    "      bias.sub <- bias.sub[as.integer(rownames(thin.sub[[1]])),]\n",
    "      if(j == 1){bias.pts <- bias.sub} else {bias.pts <- rbind(bias.pts, bias.sub)}\n",
    "      et <- Sys.time() - st\n",
    "      print(paste0(sp, ' time thin ', j, ' of ', round(et, 2), attr(et, \"units\")))\n",
    "    }\n",
    "  }\n",
    "  ## thinning sampling bias to match occurrence thinning\n",
    "  bias.thin <- spThin::thin(cbind(bias.pts, bias.pts@coords), long.col = 'decimalLongitude', lat.col = 'decimalLatitude', spec.col = 'taxa',\n",
    "                            thin.par = 50, reps = 1, max.files = 1, out.base = sp, locs.thinned.list.return = T,\n",
    "                            out.dir = op, write.files = F, write.log.file = F, verbose = F)\n",
    "  bias.pts <- bias.pts[as.integer(rownames(bias.thin[[1]])),]\n",
    "  \n",
    "  ## generating kernel density estimate (can be single sp) ##\n",
    "  kdm <- spatialEco::sp.kde(x = bias.pts, # input occurrence pts \n",
    "                            bw = 5, # kernel distance\n",
    "                            newdata = ref_lay, # reference raster\n",
    "                            standardize = T) # standardize 0 to 1\n",
    "  ## set crs and crop raster\n",
    "  kdm <- raster::resample(kdm, ref_lay)\n",
    "  kdm <- raster::mask(raster::crop(kdm, ref_lay), ref_lay)\n",
    "  names(kdm) <- \"samp_bias\"\n",
    "  setwd(sp.dir)\n",
    "  raster::writeRaster(kdm, filename = \"bias_sampling_bw5.tif\")\n",
    "  \n",
    "  #### selecting background points ####\n",
    "  br.buff <- raster(list.files(pattern = 'Br-buffer500km'))\n",
    "  kdm <- raster::mask(kdm, br.buff) # limitting bg to buffered area only\n",
    "  \n",
    "  min.buff <- raster::buffer(sp.pts, 10000) # min distance from occ\n",
    "  # plot(min.buff)\n",
    "  raster::crs(min.buff) <- CRS('+init=EPSG:4326')\n",
    "  min.buff <- raster::mask(kdm, min.buff)\n",
    "  min.buff[!is.na(min.buff)] <- 0 # raster package format edits\n",
    "  min.buff[is.na(min.buff)] <- 1 # raster package format edits\n",
    "  min.buff[min.buff == 0] <- NA # raster package format edits\n",
    "  \n",
    "  bg.area <- raster::mask(kdm, min.buff) # mask out area < min distance from occ\n",
    "  bg.area <- as.data.frame(bg.area, xy = T, cells = F, na.rm = T) # convert to df for sampling\n",
    "  bg.pts <- bg.area[sample(seq_len(nrow(bg.area)), # row identifier\n",
    "                           10000, # number of bg points\n",
    "                           replace = F,\n",
    "                           prob = bg.area$samp_bias), ] # sampling probability of each row\n",
    "  write.csv(bg.pts, file = 'bg_pts.csv', row.names = F) # tune results\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2738b-649c-4967-bd1c-bfb1f0e9a076",
   "metadata": {},
   "source": [
    "### C. Bioclimatic variables <a id='biovar'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf9eb4-03dd-429c-91cf-3d41f02f00dc",
   "metadata": {},
   "source": [
    "Obtain bioclimatic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482c4fa-bdea-4f76-bdff-9c3bf05de9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Present day (1960-1990; 30 seconds, bio): https://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio1-9_30s_bil.zip, https://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio10-19_30s_bil.zip\n",
    "2. mid-Holocene (CCSM4, 30 seconds, bi): https://biogeo.ucdavis.edu/data/climate/cmip5/mid/ccmidbi_30s.zip\n",
    "3. Last Glacial Maximum (CCSM4, 2.5 minutes, bi): https://biogeo.ucdavis.edu/data/climate/cmip5/lgm/cclgmbi_2-5m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627274aa-fe23-4638-aee7-9e0732b2fb55",
   "metadata": {},
   "source": [
    "Prepare bioclimatic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be3c42-03ea-4b85-a17f-02cf36ff752f",
   "metadata": {},
   "source": [
    "- make sure all rasters have the same nodata value and units\n",
    "- clip rasters by polygon (SAGA toolbox)\n",
    "- convert .sdat raster to .adc (Raster > Conversion > Translate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f84d1-7307-4269-839f-b362026b23d5",
   "metadata": {},
   "source": [
    "## 2. Maxent modelling <a id='maxent'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70dff8-8ff0-4e6d-9f68-9d7917b3bf54",
   "metadata": {},
   "source": [
    "Perform Maxent analyses, model selection, and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacce1e-afbd-4a65-b0be-f627a1868bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "library(ENMeval)\n",
    "library(terra)\n",
    "library(usdm)\n",
    "library(ecospat)\n",
    "\n",
    "main <- \"path/workingDirectory\"\n",
    "setwd(main)\n",
    "setwd('data')\n",
    "sp.list <- c(\"americanus\", \"arquata\", \"hudsonicus\", \"phaeopus\")\n",
    "sp <- sp.list[2]\n",
    "for(sp in sp.list) {\n",
    "  #### data preparation ####\n",
    "  setwd(main)\n",
    "  setwd('data')\n",
    "  setwd(sp); sp.dir <- getwd()\n",
    "  ## Occurrences and Background ##\n",
    "  sp.occ <- read.csv(list.files(pattern = 'occurrence'))\n",
    "  colnames(sp.occ)[2:3] <- c('x', 'y')\n",
    "  sp.occ$PA <- 1\n",
    "  bg.pts <- read.csv('bg_pts.csv')\n",
    "  bg.pts$PA <- 0\n",
    "  ip.df <- rbind(sp.occ[,c('x', 'y', 'PA')], bg.pts[,c('x', 'y', 'PA')])\n",
    "  rm(sp.occ, bg.pts)\n",
    "  br.buff <- rast(list.files(pattern = 'Br-buffer500km'))\n",
    "  \n",
    "  ## Bioclimatic variables ##\n",
    "  setwd(\"current-v1.4-r2.5\")\n",
    "  bio.var <- rast(paste0('bio', 1:19, '.asc'))  \n",
    "  ip.df[, paste0(\"bio\", 1:19)] <- terra::extract(bio.var, ip.df[, c('x', 'y')])[,-1]\n",
    "  ip.df <- ip.df[!is.na(ip.df$bio1),]\n",
    "  rm(bio.var)\n",
    "  \n",
    "  ## varbiable selection ##\n",
    "  bio.vif <- usdm::vifstep(ip.df[, paste0(\"bio\", 1:19)], th = 3)\n",
    "  bio.sel <- bio.vif@results$Variables\n",
    "  \n",
    "  ## data partitioning ##\n",
    "  cv.bins <- get.block(ip.df[ip.df$PA == 1, c('x','y')], ip.df[ip.df$PA == 0, c('x','y')])\n",
    "  setwd(sp.dir)\n",
    "  save(cv.bins, file = paste0(sp, \"_CVbins\"))\n",
    "  \n",
    "  \n",
    "  #### MaxEnt Modelling ####\n",
    "  setwd(sp.dir)\n",
    "  betas <- c(0.5, 1, 2, 3, 4)\n",
    "  fcs <- c(\"L\", \"LQ\", \"LQH\", \"LQHP\")\n",
    "  \n",
    "  # start modeling!\n",
    "    # we use the \"try\" notation so if a species fails to fit, the loop will continue\n",
    "  tune_maxent <- NULL # tuned maxent model\n",
    "  ptm <- proc.time() # record mod time\n",
    "  # train.df has multiple columns\n",
    "  # PA = presence (1) or background (0)\n",
    "  # 'x', 'y' are included as ENMevaluate automatically takes the first two columns as coordinate information even though using dataframe mean that coordinates are ignored\n",
    "  # varb.list = my list of relevant variables (e.g., bio01, bio02, land_use)\n",
    "  # Note, categoricals are used here, but user should delineate if there are any\n",
    "  # user.grp = bins for partitioning the data (cross-validation etc)\n",
    "  # partitions = 'user' as partitions were set in user.grp\n",
    "  if(inherits(try(\n",
    "    tune_maxent <- ENMeval::ENMevaluate(occs = ip.df[ip.df$PA == 1, c('x', 'y', bio.sel)],\n",
    "                                        bg = ip.df[ip.df$PA == 0, c('x', 'y', bio.sel)],\n",
    "                                        # categoricals = 'land_use',\n",
    "                                        user.grp = cv.bins, partitions = 'user',\n",
    "                                        tune.args = list(fc = fcs, rm = betas),\n",
    "                                        algorithm = 'maxent.jar', overlap = F, quiet = T,\n",
    "                                        doClamp = F, parallel = T, numCores = 10)\n",
    "  ), \"try-error\")){\n",
    "    print(paste(\"MaxEnt Tune: Error for species \", sp))\n",
    "  }\n",
    "  tt_maxent <- proc.time() - ptm\n",
    "  print(tt_maxent)\n",
    "  \n",
    "  if(!is.null(tune_maxent)) {\n",
    "    res_maxent <- tune_maxent@results # extract results table\n",
    "    write.csv(res_maxent, file = paste0(sp, '_tunemaxent.csv'), row.names = F) # tune results\n",
    "    \n",
    "    ## selecting model ##\n",
    "    mod_maxent <- res_maxent[which(res_maxent$ncoef > 1), ] # remove overly simplistic or non-converging mods\n",
    "    mod_maxent <- mod_maxent[!is.na(mod_maxent$AICc), ] # remove overly complex mods\n",
    "    mod_maxent <- mod_maxent[which(mod_maxent$or.mtp.avg <= 0.2), ] # remove underpredicting models\n",
    "    mod_maxent$cbi.val.CoV <- mod_maxent$cbi.val.sd / mod_maxent$cbi.val.avg\n",
    "    ## select based on highest AUC score\n",
    "    mod_maxent <- mod_maxent[which(mod_maxent$auc.val.avg == max(mod_maxent$auc.val.avg, na.rm = T)),] # INCASE > 1, max test AUC\n",
    "    mod_maxent <- mod_maxent[which(mod_maxent$auc.train == max(mod_maxent$auc.train, na.rm = T)),] # INCASE > 1, max test AUC\n",
    "    mod_maxent <- tune_maxent@models[[as.numeric(rownames(mod_maxent))[1]]] # extract the selected model from model list\n",
    "    rm(res_maxent, tune_maxent)\n",
    "  } else {mod_maxent <- NULL}\n",
    "  save(mod_maxent, file = paste0(sp, '_selmod'))\n",
    "  \n",
    "  #### predicting models ####\n",
    "  # select different times #\n",
    "  maxSSS <- mod_maxent@results[\"Maximum.training.sensitivity.plus.specificity.Cloglog.threshold\",]\n",
    "  for (t.period in 1:3) {\n",
    "    bio.period <- c('current-v1.4-r2.5', 'LGM-v1.4-r2.5', 'midHolocene-v1.4-r2.5')[t.period]\n",
    "    nm.period <- c('current', 'LGM', 'MH')[t.period]\n",
    "    setwd(sp.dir)\n",
    "    setwd(bio.period)\n",
    "    bio.var <- rast(paste0(bio.sel, '.asc'))\n",
    "    bio.var <- terra::mask(bio.var, br.buff)\n",
    "    setwd(sp.dir)\n",
    "    if(!file.exists('predictions')) {dir.create('predictions')}\n",
    "    setwd('predictions')\n",
    "    pred <- terra::predict(bio.var, mod_maxent, type = \"cloglog\", na.rm = T) # >= maxSSS.th # if you want binary\n",
    "    writeRaster(pred, filename = paste0(sp, '_', nm.period, '_cont.tif'), overwrite = T)\n",
    "    writeRaster(pred >= maxSSS, filename = paste0(sp, '_', nm.period, '_bina.tif'), overwrite = T)\n",
    "    rm(bio.var)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285c9f1-73d5-493c-8165-75fd1567ee49",
   "metadata": {},
   "source": [
    "## 3. Maxent results <a id='results'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804036f-df99-4467-ae41-b012c2fee7a7",
   "metadata": {},
   "source": [
    "Calculate suitable breeding area from '_bina.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899c7d5-29e6-45b1-8857-7deac489ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "library(raster)\n",
    "library(rgdal)\n",
    "library(maps)\n",
    "library(ENMTools)\n",
    "library(rgeos)\n",
    "library(sp)\n",
    "\n",
    "# set colour palette and load map\n",
    "pal <- colorRampPalette(c(\"#e6e6e6\", \"#ad8b62\", \"#f5f4cf\", \"#c2e075\", \"#84a338\", \"#4f6121\"))\n",
    "worldmap <- readOGR(dsn = \"path/map\", layer = \"ne_110m_land\")\n",
    "add.map <- function() {\n",
    "  plot(worldmap, add=TRUE)\n",
    "}\n",
    "\n",
    "# load binary raster\n",
    "rasterB <- raster(\"species_time_bina.tif\")\n",
    "# add map outline\n",
    "plot(rasterB, col = pal(100), addfun=add.map)\n",
    "\n",
    "## calculate suitable area\n",
    "# remove cells with suitability score <1 (only 2 values possible as raster has been made binary)\n",
    "# need to change variable name\n",
    "raster3<-rasterB[!(rasterB$speices_time_bina < 0.1), ]\n",
    "length(raster3)\n",
    "# get sizes of all cells in raster distribution raster\n",
    "cell_size<-area(rasterB, na.rm=TRUE, weights=FALSE)\n",
    "# delete NAs from all raster cells\n",
    "cell_size1<-cell_size[!is.na(cell_size)]\n",
    "# compute area [km2] of all cells in raster\n",
    "raster_area_present<-length(raster3)*median(cell_size1)\n",
    "raster_area_present"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
